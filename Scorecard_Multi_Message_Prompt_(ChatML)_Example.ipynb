{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xO5brg_tzz4A"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scorecard-ai/scorecard-cookbook/blob/main/Scorecard_Multi_Message_Prompt_(ChatML)_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo: Scorecard Multi-Message Prompt (ChatML)\n",
        "## 🧙‍♂️ Instructions\n",
        "\n",
        "1. Create an account and [login to Scorecard](https://app.getscorecard.ai/). Copy your [API key](https://app.getscorecard.ai/api-key).\n",
        "1. Add your Scorecard and OpenAI API Keys below.\n",
        "1. Go to `Runtime` -> `Run all`. Enjoy!"
      ],
      "metadata": {
        "id": "LjecdsSRPPai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 👉 API Keys\n",
        "\n",
        "OPENAI_API_KEY = \"\" #@param { type: \"string\" }\n",
        "SCORECARD_API_KEY = \"\" #@param { type: \"string\" }"
      ],
      "metadata": {
        "id": "wAsJ8kJ6O1TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "xO5brg_tzz4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "#@markdown In order to keep the notebook working for all future users, we pin the dependency versions.\n",
        "\n",
        "!pip install scorecard-ai==0.1.10\n",
        "!pip install openai==1.11.1"
      ],
      "metadata": {
        "id": "B_wcdhcPzyQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33ffd31-9088-4935-e7f8-df9734a88916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scorecard-ai==0.1.10\n",
            "  Downloading scorecard_ai-0.1.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m433.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.21.2 (from scorecard-ai==0.1.10)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.5.0,>=1.9.2 (from scorecard-ai==0.1.10)\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->scorecard-ai==0.1.10) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->scorecard-ai==0.1.10) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.21.2->scorecard-ai==0.1.10)\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->scorecard-ai==0.1.10) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->scorecard-ai==0.1.10) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.21.2->scorecard-ai==0.1.10)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.5.0,>=1.9.2->scorecard-ai==0.1.10) (0.6.0)\n",
            "Collecting pydantic-core==2.10.1 (from pydantic<2.5.0,>=1.9.2->scorecard-ai==0.1.10)\n",
            "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.5.0,>=1.9.2->scorecard-ai==0.1.10) (4.9.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->scorecard-ai==0.1.10) (1.2.0)\n",
            "Installing collected packages: pydantic-core, h11, pydantic, httpcore, httpx, scorecard-ai\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.16.2\n",
            "    Uninstalling pydantic_core-2.16.2:\n",
            "      Successfully uninstalled pydantic_core-2.16.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.1\n",
            "    Uninstalling pydantic-2.6.1:\n",
            "      Successfully uninstalled pydantic-2.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 pydantic-2.4.2 pydantic-core-2.10.1 scorecard-ai-0.1.10\n",
            "Collecting openai==1.11.1\n",
            "  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.11.1) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (2.4.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.11.1) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.11.1) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.11.1) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.11.1) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.11.1) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.11.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.11.1) (2.10.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-1.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "\n",
        "from openai import OpenAI\n",
        "from scorecard.client import Scorecard"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dod8Xp-5z5i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build your LLM system\n",
        "\n",
        "Now, let's define your system (aka system-under-test)! For this demo, we'll set up an LLM call to generate the opening line of a story, where the user determines what the topic of the story will be."
      ],
      "metadata": {
        "id": "PQriXDnF0CVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define our multi-message prompt template\n",
        "\n",
        "PROMPT_TEMPLATE_1 = \"You are a helpful assistant.\" #@param { type:\"string\" }\n",
        "\n",
        "PROMPT_TEMPLATE_2 = \"Assist the user in crafting a story about {user_topic}.\" #@param { type:\"string\" }\n",
        "\n",
        "PROMPT_TEMPLATE_3 = \"I need a good opening line for my story. Please generate only the opening line.\" #@param { type:\"string\" }"
      ],
      "metadata": {
        "id": "-4PGlf0UQ2pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRiB7PWwzcu_"
      },
      "outputs": [],
      "source": [
        "#@title Call OpenAI to generate a story\n",
        "#@markdown Here we'll define an example of a multi-message prompt sent to OpenAI.\n",
        "\n",
        "def generate_story(user_topic: str) -> str:\n",
        "  client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",  # or \"gpt-4\" depending on your access and requirements\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": PROMPT_TEMPLATE_1},\n",
        "        {\"role\": \"system\", \"content\": PROMPT_TEMPLATE_2.format(user_topic=user_topic)},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_TEMPLATE_3}\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate your system\n",
        "\n",
        "### Pre-req: Create Metrics\n",
        "\n",
        "First, using the Scorecard application, create your metrics and scoring config. For this example,\n",
        "we can use something simple like a Helpfulness metric that determines whether\n",
        "the generation adheres to the user's request.\n",
        "\n",
        "Once you have created your scoring config, copy the ID and enter it below:"
      ],
      "metadata": {
        "id": "YCbMNYhl4IMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure Metrics\n",
        "SCORING_CONFIG_ID = 1  #@param { type: \"number\" }"
      ],
      "metadata": {
        "id": "rWIaBWy_WvhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Create a basic Testset\n",
        "#@markdown Here we'll create a basic Testset that gets stored in Scorecard.\n",
        "\n",
        "client = Scorecard(\n",
        "    api_key=SCORECARD_API_KEY\n",
        ")\n",
        "\n",
        "# Create a Testset\n",
        "testset = client.testset.create(\n",
        "    name=\"Story Opening Lines\",\n",
        "    description=\"Demo of a testset created via Scorecard Python SDK\",\n",
        "    using_retrieval=False\n",
        ")\n",
        "\n",
        "# Add three testcases\n",
        "client.testcase.create(\n",
        "    testset_id=testset.id,\n",
        "    user_query=\"magical powers to control ice and snow\"\n",
        ")\n",
        "client.testcase.create(\n",
        "    testset_id=testset.id,\n",
        "    user_query=\"a journey with a rugged iceman, his loyal reindeer, and a naive snowman\"\n",
        ")\n",
        "client.testcase.create(\n",
        "    testset_id=testset.id,\n",
        "    user_query=\"the story of two royal sisters\"\n",
        ")\n",
        "\n",
        "print(\"Visit the Scorecard app to view your Testset:\")\n",
        "print(f\"https://app.getscorecard.ai/view-dataset/{testset.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqtQRU694Jft",
        "outputId": "b6c54408-390a-408c-a31d-c06ce50798c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit the Scorecard app to view your Testset:\n",
            "https://app.getscorecard.ai/view-dataset/786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Run Tests\n",
        "#@markdown Now we'll create a new Run to execute our LLM system above.\n",
        "\n",
        "from scorecard.types import RunStatus\n",
        "\n",
        "run = client.run.create(testset_id=testset.id)\n",
        "client.run.update_status(run_id=run.id, status=RunStatus.RUNNING_EXECUTION)\n",
        "\n",
        "for testcase in client.testset.get_testcases(testset_id=testset.id).results:\n",
        "  model_response = generate_story(user_topic=testcase.user_query)\n",
        "  client.testrecord.create(run_id=run.id,\n",
        "                           testset_id=testset.id,\n",
        "                           testcase_id=testcase.id,\n",
        "                           user_query=testcase.user_query,\n",
        "                           response=model_response)\n",
        "\n",
        "client.run.update_status(run_id=run.id, status=RunStatus.AWAITING_SCORING)\n",
        "\n",
        "print(\"Visit the Scorecard app to view your Run:\")\n",
        "print(f\"https://app.getscorecard.ai/view-records/{run.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCc2EdyeRoIH",
        "outputId": "398b3377-bab7-4f78-cd56-80bbc7ffa690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit the Scorecard app to view your Run:\n",
            "https://app.getscorecard.ai/view-records/2610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Kick off Scoring\n",
        "#@markdown Once your run above is finished executing, hit the \"Run Scoring\" button to run scoring. Once that's done, visit the Results page:\n",
        "\n",
        "print(\"Visit the Scorecard app to view your Results:\")\n",
        "print(f\"https://app.getscorecard.ai/view-grades/{run.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "TDVMDhAoWgL6",
        "outputId": "d3e50122-3fc3-4d02-f8cf-60483e0c4d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visit the Scorecard app to view your Results:\n",
            "https://app.getscorecard.ai/view-grades/2610\n"
          ]
        }
      ]
    }
  ]
}